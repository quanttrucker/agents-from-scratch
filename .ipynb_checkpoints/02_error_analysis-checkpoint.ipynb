{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1112fe-d321-4e05-a1a6-71c3ee0957f2",
   "metadata": {},
   "source": [
    "<b>Error correction in agent loop with Pydantic </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4106a302-4a4c-4ead-a871-47e163249ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7702360e-ce96-4980-9e86-93464184b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede7a32-214d-4a0a-b878-0e855d7ce7c7",
   "metadata": {},
   "source": [
    "Transform the LLM from a simple text generator into a closed-loop control system. Mathematically, the LLM is your policy $\\pi$, Pydantic is your environmental constraint $C$, and the ValidationError is the negative reward signal $-R$. The agent is now forced to adjust its trajectory until $C$ is satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc5cc6-40d0-4d21-9298-1c0d211db613",
   "metadata": {},
   "source": [
    "1. <i>Pydantic contracts</i>\n",
    "Instead of relying on loose dictionaries, we define our tool arguments as strict Pydantic models. This gives us automatic type coercion and highly descriptive error messages when things fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15bf13e0-eb21-409e-a5f4-58c84b67ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the exact schema the LLM must follow\n",
    "class DBQueryArgs(BaseModel):\n",
    "    sql_query: str = Field(description=\"The exact SQL query to execute.\")\n",
    "    max_results: int = Field(default=10, description=\"Maximum number of rows to return.\")\n",
    "\n",
    "# 2. Update the Tool Registry to include the schema\n",
    "def query_database(args: DBQueryArgs) -> str:\n",
    "    print(f\"[SYSTEM] Executing DB Query: {args.sql_query} LIMIT {args.max_results}\")\n",
    "    return '{\"users_found\": 42}'\n",
    "\n",
    "TOOL_REGISTRY = {\n",
    "    \"query_database\": {\n",
    "        \"function\": query_database,\n",
    "        \"schema\": DBQueryArgs\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e07c14-2dc0-4f8c-ad6b-e15baf1520f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(messages: list) -> dict:\n",
    "    \"\"\"\n",
    "    Simulates a call to an LLM API. \n",
    "    In production, this would use the official SDKs to return structured JSON.\n",
    "    \"\"\"\n",
    "    # ... standard API call logic here ...\n",
    "    \n",
    "    # Example simulated response where the LLM decides to use a tool:\n",
    "    return {\n",
    "        \"status\": \"tool_call\",\n",
    "        \"tool_name\": \"query_database\",\n",
    "        \"tool_args\": {\"sql_query\": \"SELECT COUNT(*) FROM users;\"}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea83c81b-a0ac-4925-8ae1-e327c31ce5d0",
   "metadata": {},
   "source": [
    "2. <i>The Self-correcting agent loop </i>\n",
    "Wrap the tool execution in a try/except block. If Pydantic throws a ValidationError, the agent intercepts it and loops back automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d363fd-971a-4508-a1ab-818899e77ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_resilient_agent(user_request: str):\n",
    "    state_memory = [{\"role\": \"system\", \"content\": \"You are a data agent.\"}]\n",
    "    state_memory.append({\"role\": \"user\", \"content\": user_request})\n",
    "    \n",
    "    step_count = 0\n",
    "    max_steps = 7 \n",
    "    \n",
    "    while step_count < max_steps:\n",
    "        step_count += 1\n",
    "        print(f\"\\n--- Reasoning Step {step_count} ---\")\n",
    "        \n",
    "        # 1. Get LLM Output\n",
    "        llm_response = call_llm(state_memory) \n",
    "        \n",
    "        if llm_response[\"status\"] == \"complete\":\n",
    "            return llm_response[\"content\"]\n",
    "            \n",
    "        elif llm_response[\"status\"] == \"tool_call\":\n",
    "            tool_name = llm_response[\"tool_name\"]\n",
    "            raw_args = llm_response[\"tool_args\"] # The messy JSON from the LLM\n",
    "            \n",
    "            tool_data = TOOL_REGISTRY.get(tool_name)\n",
    "            \n",
    "            if not tool_data:\n",
    "                # LLM hallucinated a tool name\n",
    "                error_msg = f\"Error: Tool '{tool_name}' does not exist. Available tools: {list(TOOL_REGISTRY.keys())}\"\n",
    "                state_memory.append({\"role\": \"user\", \"content\": error_msg})\n",
    "                continue # Send it right back to the LLM to try again\n",
    "                \n",
    "            # --- THE SELF-CORRECTION BLOCK ---\n",
    "            try:\n",
    "                # 2. Force the LLM's raw output through the Pydantic schema\n",
    "                validated_args = tool_data[\"schema\"](**raw_args)\n",
    "                \n",
    "                # 3. If it passes, execute the function\n",
    "                tool_result = tool_data[\"function\"](validated_args)\n",
    "                \n",
    "                # 4. Append success to memory\n",
    "                state_memory.append({\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"Tool '{tool_name}' succeeded. Result: {tool_result}\"\n",
    "                })\n",
    "                \n",
    "            except ValidationError as e:\n",
    "                # 5. Catch type mismatches or missing fields!\n",
    "                print(f\"[WARNING] LLM generated invalid arguments. Triggering auto-retry.\")\n",
    "                \n",
    "                # We feed the exact Pydantic error back into the LLM's context window\n",
    "                error_feedback = (\n",
    "                    f\"Tool '{tool_name}' failed validation.\\n\"\n",
    "                    f\"You provided: {raw_args}\\n\"\n",
    "                    f\"Pydantic Error Traceback:\\n{e.json()}\\n\"\n",
    "                    f\"Please correct your JSON arguments and call the tool again.\"\n",
    "                )\n",
    "                \n",
    "                state_memory.append({\"role\": \"user\", \"content\": error_feedback})\n",
    "                # The loop continues. The LLM reads its own error and fixes it on the next pass.\n",
    "                \n",
    "    return \"Fatal Error: Agent reached maximum steps or got stuck in an error loop.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8d017-f9b3-4721-b378-4442b29494a5",
   "metadata": {},
   "source": [
    "<b>Things to note</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfb256-924c-4410-8ec6-ca481623d102",
   "metadata": {},
   "source": [
    "The biggest point of failure in this loop is in <i> Memory Pagination </i>(the MemGPT architecture) --> if the LLM fails validation 3 times in a row, the state_memory array is going to fill up with massive, token-heavy Python tracebacks, rapidly blowing out your context window and your API budget. <br> \n",
    "Can the agent can autonomously compress or flush old tracebacks to keep the context window small and efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5fe2e-0cde-4bbe-9f5a-2a38accbca83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d019ecb-12ba-4687-a9fc-347b37ebdde8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223f26a-3614-47e3-893d-8bb0ec0cefe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
