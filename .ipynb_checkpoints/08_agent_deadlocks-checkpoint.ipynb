{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1112fe-d321-4e05-a1a6-71c3ee0957f2",
   "metadata": {},
   "source": [
    "<b>Multiple Agents - distributed Agentic AI</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4106a302-4a4c-4ead-a871-47e163249ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7702360e-ce96-4980-9e86-93464184b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede7a32-214d-4a0a-b878-0e855d7ce7c7",
   "metadata": {},
   "source": [
    "We have been building a single, highly optimized monolith. You built the context-management, the self-healing heartbeat loop, and the vector storage. In traditional software engineering terms, you have successfully containerized a single, robust Microservice. <br>\n",
    "Now, we need to build the orchestration layerâ€”the Kubernetes or API Gateway of your AI system. <br>\n",
    "When you transition to a hierarchical multi-agent framework (like Microsoft AutoGen or Letta), you stop asking the LLM to solve the problem directly. Instead, you introduce a Manager Agent whose sole purpose is routing, delegation, and state evaluation. <br>\n",
    "Here is the architectural blueprint for wrapping your robust worker nodes into a multi-agent hierarchy.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc5cc6-40d0-4d21-9298-1c0d211db613",
   "metadata": {},
   "source": [
    "<b>The Mathematical Model: The Routing Policy </b> <br> \n",
    "In a single-agent system, the action space is the set of available Python tools. In a hierarchical multi-agent system, the action space is the set of other agents. <br> \n",
    "Let $\\mathcal{W} = \\{w_1, w_2, \\dots, w_k\\}$ represent your pool of specialized worker agents (e.g., $w_1$ is a DB Query Agent, $w_2$ is a Web Search Agent). <br> \n",
    "The Manager maintains a Global State $S_{global}$ (the overarching task). Its job is to execute a routing policy $\\pi(a | S_{global})$ where the action $a \\in \\mathcal{W} \\cup \\{\\text{Final Output}\\}$. <br> \n",
    "The Manager evaluates the sub-task, selects $w_i$, waits for $w_i$'s internal heartbeat loop to reach a terminal state, and then absorbs $w_i$'s final output back into $S_{global}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500aee3-f794-4ed4-920d-7e26870f565c",
   "metadata": {},
   "source": [
    "<b> Step 1: Wrap Your Workers as Tools </b> <br>\n",
    "To make this work in pure Python (which maps exactly to how AutoGen's GroupChatManager functions under the hood), we encapsulate the run_os_agent loop we built earlier into callable functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d019ecb-12ba-4687-a9fc-347b37ebdde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1. We instantiate two isolated instances of our previous architecture\n",
    "def run_db_worker(sub_task: str) -> str:\n",
    "    \"\"\"A worker node with access to SQL tools and schema FAISS memory.\"\"\"\n",
    "    # ... executes the heartbeat loop from our previous steps ...\n",
    "    return final_worker_string \n",
    "\n",
    "def run_research_worker(sub_task: str) -> str:\n",
    "    \"\"\"A worker node with access to Web Search and document FAISS memory.\"\"\"\n",
    "    # ... executes the heartbeat loop from our previous steps ...\n",
    "    return final_worker_string\n",
    "\n",
    "# 2. We define strict Pydantic schemas for delegation\n",
    "class DelegateToDBAgent(BaseModel):\n",
    "    sub_task: str = Field(description=\"The specific SQL/Data task the worker must solve.\")\n",
    "    context: str = Field(description=\"Any prior knowledge the worker needs to know.\")\n",
    "\n",
    "class DelegateToResearchAgent(BaseModel):\n",
    "    sub_task: str = Field(description=\"The specific research question to answer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcafed3-5479-4c3f-a77f-0b5d1d160c1a",
   "metadata": {},
   "source": [
    "<b> Step 2: The Manager's Orchestration Loop </b> <br>\n",
    "The Manager has its own context window and its own loop, but it does not have access to the underlying tools (like FAISS or database connections). It only has access to the Delegation tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb84a39-9c24-48fc-8429-47c5d4b82155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_manager_agent(complex_user_request: str):\n",
    "    # 1. The Global State\n",
    "    global_memory = [\n",
    "        {\"role\": \"system\", \"content\": \"You are the Orchestrator. Break down the user's request and delegate sub-tasks to your workers. Do not answer the question yourself.\"}\n",
    "    ]\n",
    "    global_memory.append({\"role\": \"user\", \"content\": complex_user_request})\n",
    "    \n",
    "    manager_steps = 0\n",
    "    \n",
    "    while manager_steps < 5:\n",
    "        manager_steps += 1\n",
    "        print(f\"\\n[MANAGER] Evaluating Global State (Step {manager_steps})...\")\n",
    "        \n",
    "        # 2. The Routing Decision\n",
    "        llm_response = call_llm(global_memory)\n",
    "        \n",
    "        if llm_response[\"status\"] == \"complete\":\n",
    "            return llm_response[\"content\"] # The Manager compiles the final answer\n",
    "            \n",
    "        elif llm_response[\"status\"] == \"tool_call\":\n",
    "            tool_name = llm_response[\"tool_name\"]\n",
    "            args = llm_response[\"tool_args\"]\n",
    "            \n",
    "            # 3. Thread Handoff (The Manager blocks while the Worker loops)\n",
    "            print(f\"[MANAGER] Delegating to {tool_name} with task: {args['sub_task']}\")\n",
    "            \n",
    "            if tool_name == \"DelegateToDBAgent\":\n",
    "                worker_result = run_db_worker(args[\"sub_task\"])\n",
    "            elif tool_name == \"DelegateToResearchAgent\":\n",
    "                worker_result = run_research_worker(args[\"sub_task\"])\n",
    "                \n",
    "            # 4. Global State Update\n",
    "            print(f\"[MANAGER] Worker returned. Updating global state.\")\n",
    "            global_memory.append({\n",
    "                \"role\": \"system\", \n",
    "                \"content\": f\"Worker {tool_name} completed task. Result: {worker_result}\"\n",
    "            })\n",
    "            \n",
    "            # The Manager loops, reads the worker's result, and decides if it needs \n",
    "            # to delegate to the next worker or formulate the final answer to the user.\n",
    "            \n",
    "    return \"Error: Orchestrator failed to coordinate workers in time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c51e7-aee2-4c06-918b-336d098eb1c4",
   "metadata": {},
   "source": [
    "<i>How Frameworks Abstract This </i> <br>\n",
    "If you look at the code above, you can see exactly why frameworks like AutoGen and CrewAI exist. Writing these nested while loops manually becomes tedious when you have 10 agents. <br>\n",
    "\n",
    "In AutoGen (AG2): Instead of writing the DelegateTo... classes, you instantiate ConversableAgent objects. The GroupChatManager acts as the while loop, dynamically reading the chat history and calling the .generate_reply() method of the next worker agent. <br>\n",
    "\n",
    "In CrewAI: You define Task objects and assign an Agent to them. CrewAI's Process.hierarchical setting automatically spins up an LLM Manager that acts exactly like our run_manager_agent, passing the output of the DB worker as the input string to the Research worker. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cd39e-c4e5-421c-b0ba-21f5137c5b1d",
   "metadata": {},
   "source": [
    "By wrapping your robust worker nodes in this Manager loop, you now have a highly scalable architecture. The Manager handles the high-level cognitive planning $\\Psi$, while the Workers execute the granular action policies $\\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624aa58-d250-468d-8a49-3290e1fe2e91",
   "metadata": {},
   "source": [
    "However, introducing multiple autonomous agents introduces a severe complication: Inter-Agent Conflict and Infinite Arguments. What happens when your Coder Agent writes a script, your Tester Agent runs it and finds a bug, but the Coder Agent stubbornly refuses to change the logic, resulting in the two agents burning through 50 API calls arguing with each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f6a67-b9e5-460c-8795-9277aa3603ab",
   "metadata": {},
   "source": [
    "Architectural patterns for Consensus Mechanisms and Deadlock Resolution so you can forcefully break infinite loops between argumentative agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a0cdfc-1931-42a9-a23b-8687e3026e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
